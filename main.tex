% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

%\usepackage[style=splncs04]{biblatex}
%\addbibresource{../papers/papers}

\begin{document}
%
\title{New Tech in Reinforcement Learning}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Author}
%
%\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
%\institute{}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Abstract
\end{abstract}
%
%
%
\section{Introduction}

\section{Distributional Reinforcement Learning}

Ordinarily, the Bellman equation only considers the expected return of a policy. Two policies with the same expected return are considered equivalent, even if the underlying probability distributions are different and can lead to different results. Information is lost.

Distributional RL seeks to rectify this problem by considering the value distribution $Z$.

\section{Hindsight Experience Replay}

HER allows learning multi-goal tasks from sparse and binary rewards.

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
%\begin{thebibliography}{8}
%\bibliographystyle{splncs04}
%\printbibliography
%\end{thebibliography}

\end{document}